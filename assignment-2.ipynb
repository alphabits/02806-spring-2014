{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Assignment 2 - Anders H\u00f8rsted (s082382)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 1 - Naive Bayes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this part we recreate a simple Naive Bayes classifier for spam detection from the book Programming Collective Intelligence <small>(Segaran, 2007)</small> (called PCI from now on). The code for the naive bayes classifier class is found in the file <code>classifiers.py</code> in the same folder as this notebook and only a few parts of the code is included in this notebook. The parts included in the notebook isn't runable but only included to illustrate some details. The various helper functions (<code>get_words</code>, <code>sampletraing</code> etc.) is included directly in this notebook.\n",
      "\n",
      "The first step in creating the classifier is to create a method to extract features from a given email. The funtion is slightly rewritten to follow common Python coding practice and is shown below"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def get_words(doc):\n",
      "    splitter = re.compile('\\\\W*')\n",
      "    words = (s.lower() for s in splitter.split(doc) if 2 < len(s) < 20)\n",
      "    return {w: 1 for w in words}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is worth noticing that <code>get_words</code> isn't returning the word count from the document but just a flag indicating whether the word was found in the document or not."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_words(\"A test with repeating words test\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "{'repeating': 1, 'test': 1, 'with': 1, 'words': 1}"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next step is to code the base class for the classifier. In <small>(Segaran, 2007)</small> the class is called <code>classifier</code> but in this implementation it is called <code>BaseClassifier</code> to follow Python naming standards and better express its purpose. Also all the properties are renamed and the <code>defaultdict</code> class is used for the dictionaries to make the code more readable. The <code>incf</code> function is shown below as an example of the refactoring"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Is part of the BaseClassifier class\n",
      "def increase_feature_category_count(self, feature, category):\n",
      "    self.feature_category_combinations[feature][category] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With the various counting functions created we can now create the <code>train</code> function and run through the steps from page 121 in PCI"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from classifiers import BaseClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = BaseClassifier(get_words)\n",
      "cl.train('the quick brown fox jumps over the lazy dog', 'good')\n",
      "cl.train('make quick money in the online casino', 'bad')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.feature_category_count('quick', 'good')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.feature_category_count('quick', 'bad')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For convenience a <code>sampletrain</code> function is created to easily train a classifier instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samples = [\n",
      "    ['Nobody owns the water', 'good'],\n",
      "    ['the quick rabbit jump fences', 'good'],\n",
      "    ['buy pharmaceuticals now', 'bad'],\n",
      "    ['make quick money at the online casino', 'bad'],\n",
      "    ['the quick brown fox jumps', 'good']\n",
      "]\n",
      "\n",
      "def sampletrain(classifier):\n",
      "    for doc, category in samples:\n",
      "        classifier.train(doc, category)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The sampletrain function calls <code>train</code> with 5 different training samples. When calling <code>train</code> the sample is converted to a feature dictionary by the <code>get_words</code> function and the two internal count dictionaries <code>_feature_category_counts</code> and <code>_category_counts</code> are updated in the classifier instance. The two count dictionaries are used by the classifier to calculate estimates of the conditional probability $P(X | C)$ where $X$ is a feature and $C$ is a given class.\n",
      "\n",
      "The conditional probability $P(X | C)$ is the probability of a document containing the feature $X$ <strong>given we know</strong> the document belongs to the class $C$. In other words we find the proportion of documents of class $C$ that contains the feature $X$. In formula \n",
      "\n",
      "$$P(X | C) = \\frac{P(XC)}{P(C)}$$\n",
      "\n",
      "So if eg. the probability of the word 'Quick' given the category 'Good' is 0.5, this means that of all documents of the category 'Good', half of them contains the word 'Quick'. So to estimate $P(X | C)$ in our spam example we count all combinations of classes and features and saves these in the dictionary <code>_feature_category_counts</code>, and also counts the number of documents of each class and saves these in <code>_category_counts</code>. There is a problem by using this estimation method. Since the feature space is huge many features will only be present in a few training documents making the estimator very sensitive when training on small training sets. Also if a feature isn't included in the training data, the conditional probability will be 0. To avoid these problems an assumed probability is calculated. To calculate it we define a weight $w$ and an initial probability $p_0$ that is the probability of the feature if not included in the training data. If $n_x$ is the feature count across all classes and $p$ is the estimate of $P(X | C)$ the assumed probability $p_a$ becomes\n",
      "\n",
      "$$p_a = \\frac{wp_0 + n_xp}{w + n_x}$$\n",
      "\n",
      "Which is just a weighted average of the initial probability $p_0$ and the conditional probability $p$, weighted by the weight $w$ and the feature count $n_x$\n",
      "\n",
      "So far we have only talked of the conditional probability of a single feature for a given class $P(X | C)$. The probability of interest is the conditional probability of a class given a feature vector $P(C | \\mathbf{X})$. \n",
      "\n",
      "The first problem is to combine $P(C | X)$ to get $P(C | \\mathbf{X})$ and secondly to \"reverse\" $P(\\mathbf{X} | C)$ to get $P(C | \\mathbf{X})$.\n",
      "The combination of $P(X|C)$ to get $P(\\mathbf{X}|C)$ is what gives Naive Bayes its name. Without further justification it is simply assumed that the conditional probability of each feature $P(X_i | C)$ is independent. The probability of a document is therefore just the product of its features $X_i$.\n",
      "\n",
      "$$P(\\mathbf{X} | C) = \\prod_i{P(X_i|C)}$$\n",
      "\n",
      "Secondly to \"reverse\" $P(\\mathbf{X} | C)$ Bayes' Theorem is used. Bayes Theorem is just a rearangement of the multiplication rule combined with the symmetry of the multiplication rule. So starting with\n",
      "\n",
      "$$P(C\\mathbf{X}) = P(C)P(\\mathbf{X}|C)$$\n",
      "\n",
      "and\n",
      "\n",
      "$$P(C\\mathbf{X}) = P(\\mathbf{X}C) = P(\\mathbf{X})P(C|\\mathbf{X})$$\n",
      "\n",
      "gives\n",
      "\n",
      "$$P(C|\\mathbf{X}) = \\frac{P(C\\mathbf{X})}{P(\\mathbf{X})} = \\frac{P(C)P(\\mathbf{X}|C)}{P(\\mathbf{X})}$$\n",
      "\n",
      "Which combined with the Naive Bayes assumption gives\n",
      "\n",
      "$$P(C|\\mathbf{X}) = \\frac{P(C)\\prod_i{P(X_i|C)}}{P(\\mathbf{X})}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from classifiers import NaiveBayesClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = NaiveBayesClassifier(get_words)\n",
      "sampletrain(cl)\n",
      "cl.probability_of_feature_given_category('quick', 'good')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.6666666666666666"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.evidence_of_category_given_document('quick rabbit', 'good')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0.15624999999999997"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.evidence_of_category_given_document('quick rabbit', 'bad')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.05"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.probability_of_category('good')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "0.6"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = NaiveBayesClassifier(get_words)\n",
      "sampletrain(cl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.classify('quick rabbit')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "'good'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.classify('quick money')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "'bad'"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.set_threshold_for_category('bad', 3.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl.classify('quick money')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "'UNKNOWN'"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for _ in range(10): \n",
      "    sampletrain(cl)\n",
      "cl.classify('quick money')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "'bad'"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 2 - Classify tweets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this execise we wish to classify some tweets from Twitter as either a happy tweet or a sad tweet using the naive bayes classifier from part 1. The tweets are imported from the file <code>data/englishtweets.txt</code> where each tweet is on a separate line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import ifilter, product"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('data/englishtweets.txt', 'r') as f:\n",
      "    tweets = f.readlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A tweet is defined as happy if it contains a happy face <code>:)</code> or <code>:-)</code> and as sad if it contains a sad face <code>:(</code> or <code>:-(</code>. Only tweets that are either happy or sad but not both are used for classification."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def has_happy_face(tweet):\n",
      "    return ':)' in tweet or ':-)' in tweet\n",
      "\n",
      "def has_sad_face(tweet):\n",
      "    return ':(' in tweet or ':-(' in tweet\n",
      "\n",
      "def tweet_mood_is_defined(tweet):\n",
      "    return has_happy_face(tweet) ^ has_sad_face(tweet)\n",
      "\n",
      "def get_tweet_category(tweet):\n",
      "    return 'happy' if has_happy_face(tweet) else 'sad'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweets_with_mood = ifilter(tweet_mood_is_defined, tweets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have all tweets with a well defined mood. Next we wish to remove all Twitter usernames from the tweets. A Twitter username is started with an @ and followed by between 1 and 15 alphanumeric characters (including underscore). To clean the tweets a simple regular expression is used. Notice that the character class <code>\\w</code> is exactly the allowed characters in a Twitter username. The character class <code>\\W</code> is just the negation of <code>\\w</code> and <code>(?&lt;=...)</code> and <code>(?=...)</code> are just positive look-behind and look-ahead groups."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twitter_username_pattern = r'(?<=\\W)@\\w{1,15}(?=\\W)'\n",
      "def clean_tweet(tweet):\n",
      "    return re.sub(twitter_username_pattern, \" \", \" \"+tweet+\" \").strip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_tweets = map(clean_tweet, tweets_with_mood)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With the tweets cleaned we are ready to train a classifier on the tweets. First we split the tweets in a training set and a test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split_index = len(clean_tweets) / 2\n",
      "training_data, test_data = clean_tweets[:split_index], clean_tweets[split_index:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we train the classifier on the training set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cl = NaiveBayesClassifier(get_words)\n",
      "for tweet in training_data:\n",
      "    cl.train(tweet, get_tweet_category(tweet))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To classify the tweets in the test set we need to set the thresholds of the two classes 'sad' and 'happy'. To be able to quickly calculate the effect of different thresholds, the <code>classify</code> method of <code>NaiveBayesClassifier</code> has been refactored into two methods <code>evidences_of_categories_given_documents</code> and <code>classify_from_evindences</code>. In this way we only call the expensive <code>evidences_of_categories_given_documents</code> once and then calls the <code>classify_from_evindences</code> for each combination of thresholds we wish to test. See the file <code>classifiers.py</code> for details.\n",
      "\n",
      "First evidences for all tweets in the test set are calculated"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classification_results = [{\"evidences\": cl.evidences_of_categories_given_document(tweet),\n",
      "                           \"category\": get_tweet_category(tweet)} for tweet in test_data]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we calculate a base line precision for a classifier that always classifies a tweet as 'happy'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_proportion_satisfied_by_filter(iterable, filter_function):\n",
      "    return len(filter(filter_function, iterable)) / float(len(iterable))\n",
      "\n",
      "get_proportion_satisfied_by_filter(test_data, has_happy_face)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "0.7449043558209565"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally we classify the tweets in the test set with various combinations of thresholds for the 'happy' and 'sad' classes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for happy_threshold, sad_threshold in product([1, 3, 7], [1, 3, 7]):\n",
      "    cl.set_threshold_for_category('happy', happy_threshold)\n",
      "    cl.set_threshold_for_category('sad', sad_threshold)\n",
      "    results = [{\"category\": c[\"category\"], \"pred\": cl.classify_from_evidences(c[\"evidences\"])} for c in classification_results]\n",
      "    results_with_prediction = filter(lambda r: r[\"pred\"] in ('happy', 'sad'), results)\n",
      "    sad_proportion = get_proportion_satisfied_by_filter(results_with_prediction, lambda r: r[\"category\"]=='sad')\n",
      "    accuracy = get_proportion_satisfied_by_filter(results_with_prediction, lambda r: r[\"pred\"]==r[\"category\"])\n",
      "    print happy_threshold, sad_threshold, accuracy, len(results_with_prediction), sad_proportion"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 1 0.794119490795 861422 0.255095644179\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3 0.806684641667 796662 0.223843989044\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7 0.809458866133 772101 0.208077699679\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 0.834795566308 746917 0.22196442175\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3 0.853331417841 682157 0.182321664954\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7 0.858330950918 657596 0.162259198657\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 0.865505670857 622569 0.202591198727\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3 0.891738928558 557809 0.151862017285\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7 0.899673322732 533248 0.125718239918\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 3 - Decision Tree overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this part we give a high level overview of the decision tree classification method. A trained decision tree is a tree of questions for a single data row. Given a row that should be classified we start at the decision tree root and follows the branch which matches the right answer for the given row. This procedure is repeated until a leaf node is reached and the class label of the leaf node is then the classification of the decision tree. For the general decision tree each node can have multiple answers (branches) but in this exercise we only work with decision trees with binary splits.\n",
      "\n",
      "If eg. we have trained the decision tree shown in figure 7.1 in PCI and the following row should be classified\n",
      "\n",
      "<code>{\n",
      "    \"color\": \"red\", \n",
      "    \"shape\": \"round\", \n",
      "    \"diameter\": 1, \n",
      "    \"stone\": True\n",
      "}</code>\n",
      "\n",
      "Starting at the root node the answer to the question <code>color = \"green\"</code> is no. Next question is <code>color = \"red\"</code> and the answer is yes. Next question is <code>diameter > 2</code> and the answer is no. The final question is <code>stone = True</code> and the answer is yes. We now arrive at a leaf node with the class label <code>Cherry</code> so the classification for the above row is Cherry."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As may be clear from the above example the decision tree has some attractive properties. First of all the classification process for a new data row is completely transparent and can be understood by all users of the decision tree. This transparency can lead to insights into the domain of the classification. Eg. users from Google never becomes paying customers etc. Secondly the decision tree can handle both categorical and numerical data as input. A third attraction of decision trees is that it is an non-parametric classification method which means that it doesn't make any prior assumptions regarding the probability distribution of the class or the input attributes."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training a decision tree"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section it is shown how a decision tree is trained using the CART algorithm as described in PCI. Starting with a full training set containing the various attributes and the known target class a root node is created. Next all possible questions for the data set are iterated. To generate all possible questions each attribute is iterated and for each attribute all unique values for this attribute in the data set is found. For each unique value a question is generated. The question is either of the form <code>attribute==value</code> or <code>attribute>=value</code> depeding on whether the attribute is categorical or numerical. To choose the question to use for a node an impurity measure $I$ is used. For each question the data set is divided into two new sets. One \"true\"-set with all rows satisfying the question and a \"false\"-set with rows not satisfying the question and a weighted average of the impurity of the two new sets is calculated. The question that gives the smallest weighted average is chosen as question for this node, as long as the weighted average is less than the impurity of the combined \"true\"- and \"false\"-set. If the weighted average is larger than the impurity of the parent node a leaf node is created containing the target class distribution. The described procedure is applied recursively to bulid the decision tree.\n",
      "\n",
      "To actually run the above training algorithm we need to select an impurity measure. In PCI two measures are mentioned. Gini Impurity and Entropy. Gini Impurity is the error rate if a random class is selected from the class distribution and used for classification of all rows in the dataset. Entropy is as defined in information theory and describes the amount of disorder in a distribution."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 4 - Modeling house prices with a decision tree"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this exercise we need to model home prices using a decision tree. First we need to fetch data from the zillow api. For this the code in <code>zillow.py</code> was completely rewritten to make it more readable and so that the xml-files could be downloaded and the data loaded from these files. See the file <code>zillow.py</code> for details."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import zillow"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To call the zillow api and save the results in xml-files in the folder <code>data/zillow</code> we call the <code>save_all_zillow_data</code>. To avoid accidentally calling the api the line is commented"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# zillow.save_all_zillow_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To load all housing data from the downloaded xml files we call <code>get_price_list</code> and filters <code>None</code> items returned from xml-files that returned an error code."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = filter(bool, zillow.get_price_list())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import treepredict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "housetree = treepredict.buildtree(data, scoref=treepredict.variance)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "treepredict.printtree(housetree)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3:3.0? \n",
        "T-> 2:1903? \n",
        "  T-> 1:SingleFamily? \n",
        "    T-> 2:1956? \n",
        "      T-> 2:2009? \n",
        "        T-> {'3519557': 1}\n",
        "        F-> {'1077490': 1}\n",
        "      F-> {'3604332': 1}\n",
        "    F-> 0:02138? \n",
        "      T-> 1:Duplex? \n",
        "        T-> {'1426404': 1}\n",
        "        F-> {'2293268': 1}\n",
        "      F-> {'1157271': 1}\n",
        "  F-> 2:1884? \n",
        "    T-> 0:02140? \n",
        "      T-> 1:Duplex? \n",
        "        T-> {'860829': 1}\n",
        "        F-> {'950341': 1}\n",
        "      F-> {'955519': 1}\n",
        "    F-> 2:1873? \n",
        "      T-> {'998342': 1}\n",
        "      F-> {'971294': 2}\n",
        "F-> 2:1903? \n",
        "  T-> 0:02138? \n",
        "    T-> 2:1925? \n",
        "      T-> 1:Condominium? \n",
        "        T-> 2:1985? \n",
        "          T-> {'910026': 1}\n",
        "          F-> {'438105': 1}\n",
        "        F-> 1:SingleFamily? \n",
        "          T-> {'480359': 1}\n",
        "          F-> {'684834': 1}\n",
        "      F-> 2:1914? \n",
        "        T-> 2:1920? \n",
        "          T-> {'538452': 1}\n",
        "          F-> {'507421': 1}\n",
        "        F-> {'392940': 1}\n",
        "    F-> 0:02139? \n",
        "      T-> 2:1987? \n",
        "        T-> 2:1996? \n",
        "          T-> {'368280': 1}\n",
        "          F-> {'665518': 1}\n",
        "        F-> {'393828': 1}\n",
        "      F-> 0:02140? \n",
        "        T-> 2:1998? \n",
        "          T-> {'215266': 1}\n",
        "          F-> {'480477': 1}\n",
        "        F-> 1:SingleFamily? \n",
        "          T-> {'609695': 1}\n",
        "          F-> {'437774': 1}\n",
        "  F-> 0:02139? \n",
        "    T-> 1:Duplex? \n",
        "      T-> 5:10? \n",
        "        T-> 2:1873? \n",
        "          T-> {'746747': 1}\n",
        "          F-> {'730522': 1}\n",
        "        F-> 2:1894? \n",
        "          T-> {'617353': 1}\n",
        "          F-> {'707421': 1}\n",
        "      F-> 1:SingleFamily? \n",
        "        T-> 2:1873? \n",
        "          T-> {'568767': 1}\n",
        "          F-> {'929651': 1}\n",
        "        F-> {'738509': 1}\n",
        "    F-> 0:02140? \n",
        "      T-> 3:2.5? \n",
        "        T-> 5:12? \n",
        "          T-> {'2170900': 1}\n",
        "          F-> {'1503176': 1}\n",
        "        F-> 1:SingleFamily? \n",
        "          T-> {'610666': 1}\n",
        "          F-> {'364980': 1}\n",
        "      F-> 2:1900? \n",
        "        T-> 3:1.5? \n",
        "          T-> {'570908': 1}\n",
        "          F-> {'484244': 1}\n",
        "        F-> 1:SingleFamily? \n",
        "          T-> {'589476': 1}\n",
        "          F-> {'587866': 1}\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 5 - PageRank algorithm"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this exercise we need to calculate the page rank for the pages in the wikispeedia data set. First a few libs are loaded"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "from operator import itemgetter\n",
      "import urllib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And a few helper functions are defined"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def include_line(line):\n",
      "    return line.strip() and not line.startswith(\"#\")\n",
      "\n",
      "def parse_line(line):\n",
      "    return map(urllib.unquote, line.strip().split(\"\\t\"))\n",
      "\n",
      "def get_tsv_file(filepath):\n",
      "    with open(filepath, 'r') as f:\n",
      "        return [parse_line(l) for l in f.readlines() if include_line(l)]\n",
      "    \n",
      "def flatten_list(list_of_lists):\n",
      "    return [item for lst in list_of_lists for item in lst]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The links are loaded from the tsv file and the incoming and outgoing links are saved in separate dictionaries to speed up the page rank calculation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "links = get_tsv_file('data/wikispeedia/links.tsv')\n",
      "\n",
      "incoming_links = defaultdict(list)\n",
      "outgoing_links = defaultdict(list)\n",
      "\n",
      "for source, target in links:\n",
      "    outgoing_links[source].append(target)\n",
      "    incoming_links[target].append(source)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All page names are loaded"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pages = flatten_list(get_tsv_file('data/wikispeedia/articles.tsv'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And we are ready to calculate the page rank for the data set. The function to actually calculate the page rank is shown below"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calculate_page_rank(pages, incoming_links, outgoing_links, damping=0.85, iterations=20):\n",
      "    initial_page_rank = 1 - damping\n",
      "    page_ranks = defaultdict(lambda: 1.0)\n",
      "    for i in range(iterations):\n",
      "        for page in pages:\n",
      "            page_rank_from_links = sum(page_rank_contribution_from_linker(linker, page_ranks, outgoing_links) \n",
      "                                       for linker in incoming_links[page])\n",
      "            page_ranks[page] = initial_page_rank + damping*page_rank_from_links\n",
      "    return page_ranks\n",
      "    \n",
      "                \n",
      "def page_rank_contribution_from_linker(linker, page_ranks, outgoing_links):\n",
      "    return page_ranks[linker] / len(outgoing_links[linker])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using this function the page ranks are calculated and sorted"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "page_ranks = calculate_page_rank(pages, incoming_links, outgoing_links)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "page_ranks_sorted = sorted(page_ranks.items(), key=itemgetter(1), reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With the page ranks now sorted we first look at the 50 highest ranked pages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "page_ranks_sorted[:50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "[('United_States', 43.86271908314403),\n",
        " ('France', 29.553887757484876),\n",
        " ('Europe', 29.12801151300175),\n",
        " ('United_Kingdom', 28.648757988841773),\n",
        " ('English_language', 22.357114419056902),\n",
        " ('Germany', 22.17729001518476),\n",
        " ('World_War_II', 21.718383201782128),\n",
        " ('England', 20.513046223889774),\n",
        " ('Latin', 20.245812476931345),\n",
        " ('India', 18.57661209279798),\n",
        " ('Japan', 17.8625992347525),\n",
        " ('Italy', 17.106790082423377),\n",
        " ('Spain', 16.765916880435768),\n",
        " ('China', 16.39328196455214),\n",
        " ('Russia', 16.08758611900355),\n",
        " ('Time_zone', 15.987620538608489),\n",
        " ('Canada', 15.74719618161901),\n",
        " ('Currency', 14.944010020425432),\n",
        " ('Australia', 14.684775897371761),\n",
        " ('Africa', 14.563745012676183),\n",
        " ('London', 14.112744260024817),\n",
        " ('Christianity', 13.91848344889303),\n",
        " ('List_of_countries_by_system_of_government', 13.083200509744675),\n",
        " ('Animal', 12.983296657493314),\n",
        " ('United_Nations', 12.947261648178973),\n",
        " ('French_language', 12.611028795892958),\n",
        " ('Islam', 12.542263783759374),\n",
        " ('North_America', 12.39808677432837),\n",
        " ('World_War_I', 11.784635187873556),\n",
        " ('Scientific_classification', 11.684234458455965),\n",
        " ('Egypt', 11.216480135118314),\n",
        " ('19th_century', 11.11948315717913),\n",
        " ('Portugal', 10.956424620917769),\n",
        " ('20th_century', 10.834724550668652),\n",
        " ('Earth', 10.707965433000098),\n",
        " ('European_Union', 10.674526740427703),\n",
        " ('Netherlands', 10.545451387671426),\n",
        " ('Asia', 10.357495989430856),\n",
        " ('Soviet_Union', 10.339235313100447),\n",
        " ('Paris', 10.238788697682574),\n",
        " (\"People's_Republic_of_China\", 10.219825039795987),\n",
        " ('Roman_Empire', 9.851509954574434),\n",
        " ('Scotland', 9.82185782465068),\n",
        " ('Middle_Ages', 9.796522176198748),\n",
        " ('Atlantic_Ocean', 9.666171042625448),\n",
        " ('Sweden', 9.433856762220556),\n",
        " ('Roman_Catholic_Church', 9.251259183077178),\n",
        " ('German_language', 9.235574879202888),\n",
        " ('Jew', 9.03036219917952),\n",
        " ('Agriculture', 8.9192262766677)]"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Based on this top 50 list it seems that western countries, the two world wars and some of the major religions are the most probable pages to come by if surfing randomly.\n",
      "\n",
      "The bottom 20 is given by"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "page_ranks_sorted[-20:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "[('San_Francisco_garter_snake', 0.15000000000000002),\n",
        " ('Sand_shark', 0.15000000000000002),\n",
        " ('Pop_Idol', 0.15000000000000002),\n",
        " ('Bourbonnais_train_accident', 0.15000000000000002),\n",
        " ('Introduction_to_special_relativity', 0.15000000000000002),\n",
        " ('Anton_Alexander_von_Werner', 0.15000000000000002),\n",
        " ('Colditz_Castle', 0.15000000000000002),\n",
        " ('Electronic_amplifier', 0.15000000000000002),\n",
        " ('Radhanite', 0.15000000000000002),\n",
        " ('Black_widow_spider', 0.15000000000000002),\n",
        " ('Arp2_3_complex', 0.15000000000000002),\n",
        " ('Uffington_White_Horse', 0.15000000000000002),\n",
        " ('Warsaw_Uprising_(1794)', 0.15000000000000002),\n",
        " ('European_Kingfisher', 0.15000000000000002),\n",
        " ('J\\xc3\\xb3rv\\xc3\\xadk', 0.15000000000000002),\n",
        " ('Fur_language', 0.15000000000000002),\n",
        " ('Emma_Roberts', 0.15000000000000002),\n",
        " ('Atlantic_herring', 0.15000000000000002),\n",
        " ('Moorhen', 0.15000000000000002),\n",
        " ('Civil_War_token', 0.15000000000000002)]"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "which consists of pages with no incoming links which makes their page rank equal to the initial page rank of 0.15"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 6 - Counting links from surf path data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paths_completed = get_tsv_file('data/wikispeedia/paths_finished.tsv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paths = (row[3] for row in paths_completed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "page_visits = [page for path in paths for page in path.split(\";\") if page != '<']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts = Counter(page_visits)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_counts = sorted(counts.items(), key=itemgetter(1), reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_counts[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "[('United_States', 8896),\n",
        " ('Europe', 4362),\n",
        " ('United_Kingdom', 3904),\n",
        " ('England', 3332),\n",
        " ('Earth', 3223),\n",
        " ('Africa', 2796),\n",
        " ('World_War_II', 2301),\n",
        " ('North_America', 1884),\n",
        " ('Germany', 1769),\n",
        " ('Animal', 1713),\n",
        " ('Human', 1642),\n",
        " ('Mammal', 1622),\n",
        " ('France', 1617),\n",
        " ('Computer', 1552),\n",
        " ('Science', 1497),\n",
        " ('English_language', 1430),\n",
        " ('Periodic_table', 1413),\n",
        " ('Atlantic_Ocean', 1324),\n",
        " ('Brain', 1324),\n",
        " ('Telephone', 1252)]"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = float(len(page_visits))\n",
      "sorted_proportions = [(row[0], row[1]/n) for row in sorted_counts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip(sorted_proportions[:20], page_ranks_sorted[:20])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "[(('United_States', 0.027270191314370494),\n",
        "  ('United_States', 43.86271908314403)),\n",
        " (('Europe', 0.01337146745877744), ('France', 29.553887757484876)),\n",
        " (('United_Kingdom', 0.011967494030047484), ('Europe', 29.12801151300175)),\n",
        " (('England', 0.010214059966218806), ('United_Kingdom', 28.648757988841773)),\n",
        " (('Earth', 0.009879926551957746), ('English_language', 22.357114419056902)),\n",
        " (('Africa', 0.008570981892421302), ('Germany', 22.17729001518476)),\n",
        " (('World_War_II', 0.007053587029492638),\n",
        "  ('World_War_II', 21.718383201782128)),\n",
        " (('North_America', 0.005775296811631522), ('England', 20.513046223889774)),\n",
        " (('Germany', 0.005422770732365266), ('Latin', 20.245812476931345)),\n",
        " (('Animal', 0.005251105858983437), ('India', 18.57661209279798)),\n",
        " (('Human', 0.005033459323088619), ('Japan', 17.8625992347525)),\n",
        " (('Mammal', 0.0049721504397379655), ('Italy', 17.106790082423377)),\n",
        " (('France', 0.004956823218900302), ('Spain', 16.765916880435768)),\n",
        " (('Computer', 0.00475756934801068), ('China', 16.39328196455214)),\n",
        " (('Science', 0.004588969918796384), ('Russia', 16.08758611900355)),\n",
        " (('English_language', 0.004383585159571696),\n",
        "  ('Time_zone', 15.987620538608489)),\n",
        " (('Periodic_table', 0.004331472608723641), ('Canada', 15.74719618161901)),\n",
        " (('Atlantic_Ocean', 0.004058648077813235), ('Currency', 14.944010020425432)),\n",
        " (('Brain', 0.004058648077813235), ('Australia', 14.684775897371761)),\n",
        " (('Telephone', 0.0038379360977508835), ('Africa', 14.563745012676183))]"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Seagaran, Toby. (2007) - <em>Programming Collective Intelligence</em> - O'Reilly Media"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}